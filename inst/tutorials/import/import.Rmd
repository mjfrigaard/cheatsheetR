---
title: "Data import with readr, readxl, and googlesheets4"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
    df_print: default
    includes:
      in_header: resizer.html
runtime: shiny_prerendered
description: >
  Import data from .csv, .xlsx, and googlesheets.
---

```{r setup, include = FALSE}
library(learnr)
library(tidyverse)
library(googlesheets4)
library(skimr)
library(knitr)
library(readxl)
library(reactable)
library(writexl)
library(openxlsx)
# pipe url: https://bit.ly/01-file-txt ----
# CSV url: https://bit.ly/01-file-csv ----
# CSV2 url: https://bit.ly/01-file2-csv ----
# TSV url: https://bit.ly/01-file-tsv ----
# f1.csv: https://bit.ly/01-f1-csv ----
# f2.csv: https://bit.ly/01-f2-csv ----
# f3.csv: https://bit.ly/01-f3-csv ----
knitr::opts_chunk$set(error = TRUE,
  upload.fun = imgur_upload, 
  exercise.cap = "import")
```

> "The tidyverse provides several packages for importing data into R and this cheatsheet covers three of them."

## The cheatsheet 

Access the cheatsheet [here](https://github.com/rstudio/cheatsheets/blob/main/data-import.pdf).

```{r 01-import-p1.png, echo=FALSE, fig.align='left', out.height='80%', out.width='80%'}
knitr::include_graphics(path = "https://raw.githubusercontent.com/mjfrigaard/learnr-cheatsheets/main/rscs-01-import/www/01-import-p1.png")
```

```{r 01-import-p2.png, echo=FALSE, fig.align='right', out.height='80%', out.width='80%'}
knitr::include_graphics(path = "https://raw.githubusercontent.com/mjfrigaard/learnr-cheatsheets/main/rscs-01-import/www/01-import-p2.png")
```

This cheatsheet covers importing data of various formats into RStudio. We're going to show how this looks on your machine (with examples). 

Below we install and load the packages:

```{r packages, eval=FALSE}
install.packages(c("readr", "googlesheets4"))
library(readr)
library(googlesheets4)
```


## Data files 

Below is an example of the data files used in this tutorial on macOS. We can see each file name and extension is associated with a different 'Kind' (or type).

```{r files-folder.png, echo=FALSE, fig.align='center', out.height='90%', out.width='90%'}
knitr::include_graphics(path = "https://raw.githubusercontent.com/mjfrigaard/learnr-cheatsheets/main/rscs-01-import/www/files-folder.png")
```

You can download the data uses in this example [here](https://github.com/mjfrigaard/cheatsheetR/raw/main/assets/import-data.zip).

We'll assume each data file is located in a `data/` folder like the one printed below: 

```{r data-tree, eval=TRUE, echo=FALSE}
fs::dir_tree("data")
```


## Plain text files (`readr`)

There are four primary functions for importing delimited files: `read_delim()`, `read_csv()`, `read_csv2()`, and `read_tsv()`. 

We can also import plain text files by clicking *Import Dataset* in the **Environment** pane (see below:)

```{r env-pane.png, echo=FALSE, fig.align='center', out.height='50%', out.width='50%'}
knitr::include_graphics(path = "https://raw.githubusercontent.com/mjfrigaard/learnr-cheatsheets/main/rscs-01-import/www/env-pane.png")
```

As we can see from the drop-down options, `readr`'s functions are designed to work with 'Text' (or 'plain text') files. R comes 'out of the box' with other functions for importing plain text files, but we won't cover those here. 

### Delimited files 

> "Read files with any delimiter. If no delimiter is specified, it will automatically guess"

All `readr` functions will import data from a local file *or* web URL. Below we use a the local data folder for the `file.txt` data, which has the following structure:

```{r file-txt.png, echo=FALSE, fig.align='center', out.height='50%', out.width='50%'}
knitr::include_graphics(path = "https://raw.githubusercontent.com/mjfrigaard/learnr-cheatsheets/main/rscs-01-import/www/file-txt.png")
```

Click 'Run Code' to see the imported file:

```{r read_delim-file-txt, exercise=TRUE}
# identical to:
# readr::read_delim(file = "https://bit.ly/01-file-txt")
readr::read_delim(file = "data/file.txt")
```


These are sometimes called [pipe-delimited flat files](https://en.wikipedia.org/wiki/Delimiter-separated_values), and their extension is usually `.txt` or `.dat`.

As we can see, if we do not specify a `delim =` argument, `read_delim()` will guess based on the contents of `data/file.txt`.

Provide the `delim = ` argument for fun (just remember to include it in quotes):

```{r read_delim-file-txt-delim, exercise=TRUE, exercise.lines = 3}
# identical to:
# readr::read_delim(file = "https://bit.ly/01-file-txt", delim = )
readr::read_delim(file = "data/file.txt", delim = " ")
```

As we can see, we get the same result as the image above. 

### Comma-separated values files (period decimals)

> "Read a comma delimited file with period decimal marks"

The `read_csv()` function will import a comma-separated values (csv) file, like the one we have in `data/file.csv`:

```{r file-csv.png, echo=FALSE, fig.align='center', out.height='50%', out.width='50%'}
knitr::include_graphics(path = "https://raw.githubusercontent.com/mjfrigaard/learnr-cheatsheets/main/rscs-01-import/www/file-csv.png")
```

We've added a few decimal point values for demonstration purposes. 

The URL for `file.csv` is below:

```markdown
https://bit.ly/01-file-csv
```

Place either the local path (`data/file.csv`) or the URL in the `file =` argument and click 'Run Code' to see the imported file:

```{r file-csv-read_csv, exercise=TRUE}
# identical to:
# read_csv(file = "https://bit.ly/01-file-csv")
readr::read_csv(file = "")
```

### Semicolon-separated values files (comma decimals)

> "Read semicolon delimited files with comma decimal marks."

Some datasets (like those from Sweden or Germany), will use commas for decimals (i.e. `0.5` = `0,5`) and semicolons as a delimiter (instead of pipes, tabs, or commas).

We have an example in `data/file2.csv`:

```{r file2-csv.png, echo=FALSE, fig.align='center', out.height='50%', out.width='50%'}
knitr::include_graphics(path = "https://raw.githubusercontent.com/mjfrigaard/learnr-cheatsheets/main/rscs-01-import/www/file2-csv.png")
```

To import these files, use the `read_csv2()` function. 


The URL for the `file2.csv` is below:

```markdown
https://bit.ly/01-file2-csv
```

Place either the local path (`data/file2.csv`) or the URL in the `file =` argument and click 'Run Code' to see the imported file:

```{r read_csv2-file2-csv, exercise=TRUE}
# identical to: 
# read_csv2(file = "https://bit.ly/01-file2-csv")
readr::read_csv2(file = "")
```

As we can see, `readr` tells us what was used as a `decimal` (as well as the `grouping mark`) and the `delimiter`.

### Tab-separated values files

> "Read a tab delimited file."

Tab-separated files are similar to comma-separated value files, except instead of using commas to delimit each value, they use tabs. In a text editor, these files appear to have white space between the values:

```{r file-tsv-png, echo=FALSE, fig.align='center', out.height='50%', out.width='50%'}
knitr::include_graphics(path = "https://raw.githubusercontent.com/mjfrigaard/learnr-cheatsheets/main/rscs-01-import/www/file-tsv.png")
```

You might be wondering how `readr` can differentiate the white space *between values on the same line* and the white space *between rows*? This is because the white space between values contains a [special character](https://en.wikipedia.org/wiki/Tab_key#Tab_characters) used to identify tabs (`\t`). This is different from the special character used to identify a new row (or [Newline](https://en.wikipedia.org/wiki/Newline)), which  is `\n`.

The URL for `file.tsv` is below. 

```markdown
https://bit.ly/01-file-tsv
```

Place either the local path (`data/file.tsv`) or the URL in the `file =` argument and click 'Run Code' to see the imported file:

```{r read_tsv-file-tsv, exercise=TRUE}
# identical to:
# readr::read_tsv(file = "data/file.tsv")
read_tsv(file = )
```


This comes in handy, because it means we can manually type the contents of a text file *directly* into any `read_*()` functions. Try it below: 

```markdown
# copy the lines below:
A\tB\tC\n1.5\t2\t3\n4.5\t5\tNA
```

```{r copy-readr, exercise=TRUE}
# paste the data between the quotes in read_delim()
readr::read_delim(file = "paste here")
```

### Delimited files (notes)

A few things to note when importing 'Text' files with `readr`: 

1. All data imported with `readr` functions are imported as a `tibble`.

2. `readr` gives us a lot of information whenever it imports a file (see below):

```{r read-delim-specs.png, echo=FALSE, fig.align='center', out.height='100%', out.width='100%'}
knitr::include_graphics(path = "https://raw.githubusercontent.com/mjfrigaard/learnr-cheatsheets/main/rscs-01-import/www/read-delim-specs.png")
```

Depending on which function you use, this will include the delimiter, decimal, column names, dimensions and column specifications (which we will cover in the next sections).

## `readr` import arguments

In this section we'll cover some additional arguments to give you more control over your imported datasets. 

### Column names (Headers)

> "No header."

If your dataset doesn't have column names, you can omit these with `col_names = FALSE`. 

Remove the column names and click 'Run Code' to see the imported file:

```{r col_names, exercise=TRUE}
# identical to:
# readr::read_csv(file = "https://bit.ly/01-file-csv", 
#                 col_names = FALSE)
readr::read_csv(file = "data/file.csv",
                col_names = )
```


The default behavior is to name these columns `X1`, `X2`, `X3`, etc. However, you can also specify the column names as a string vector (i.e., `c("x", "y", "z")`)

> "Provide header."

Change the column names from `A`, `B`, `C` to `x`, `y`, `z` and click 'Run Code' to see the imported file:

```{r supply-col_names, exercise=TRUE}
# identical to:
# readr::read_csv(file = "https://bit.ly/01-file-csv", 
#                col_names = c("x", "y", "z"))
readr::read_csv(file = "data/file.csv",
                  col_names = )
```

### Skip lines 

If there are lines we'd like to omit from our data file, we can use the `skip` argument and give a number of the lines we'd like to exclude.  

Skip the first line and click 'Run Code' to see the imported file:

```{r skip-lines, exercise=TRUE}
# identical to:
# readr::read_csv(file = "https://bit.ly/01-file-csv", 
#                 skip = 1)
readr::read_csv(file = "data/file.csv", skip = )
```

### Import multiple files 

> "Read multiple files into a single table."

We can also import multiple .csv files using a single call to `read_csv()`. Simply combine the names of the files in the `file` argument (in this case, it's three URLs.). We also supply an `id` argument, which will allow us to identify the original data file. 

Provide a name for the `id` variable (in quotes) and click 'Run Code' to see the imported files. 

```{r id-multiple, exercise=TRUE}
# identical to: 
# readr::read_csv(file = c("https://bit.ly/01-f1-csv", 
# "https://bit.ly/01-f2-csv", "https://bit.ly/01-f3-csv"), id = )
readr::read_csv(file = c("data/f1.csv", "data/f2.csv", 
                         "data/f3.csv"), id = ' ')
```

### Control imported rows

> "Read a subset of lines."

If we have a large dataset and would like to control the number of imported rows, we can use the `n_max` argument to set the maximum number of lines to read: 

Set the maximum number of rows to `2` and click 'Run Code' to see the imported file.

```{r n_max, exercise=TRUE}
# identical to:
# readr::read_csv(file = "https://bit.ly/01-file-csv", 
#                 n_max = )
readr::read_csv(file = "data/file.csv", n_max = )
```

### Set missing values 

> "Read values as missing."

We can also specify the values we'd like to set as 'missing'. By default, R detects `NA` as missing, but we can set this to whatever we want with the `na` argument (note that this needs to be a string).

Set the missing values to `1` (as a string) and click 'Run Code' to see the imported file.

```{r na, exercise=TRUE}
# identical to:
# readr::read_csv(file = "https://bit.ly/01-file-csv", 
#                 na = c("1"))
readr::read_csv(file = "data/file.csv", na = )
```


### Control formatting

> "Specify decimal marks."

Data conventions vary from place to place (as we saw before with the `file2.csv` example above). The `locale` argument gives us the ability to change the time zone, encoding, decimal mark, day/month names and more. 

The syntax is a little tricky--you'll actually use the `local` argument with the `locale()` function, like so:

```{r locale-decimal_mark, exercise=TRUE}
# identical to:
# read_delim(file = "https://bit.ly/01-file2-csv", 
#           locale = locale(decimal_mark = ","))
read_delim(file = "data/file2.csv",
           locale = locale(decimal_mark = ","))

```

As we can see, the commas have been treated as decimals. 

## `readr` column specification 

As we've seen, `readr` display a lot of useful information on imported files. However, there is even more information in contained in the column specifications, or `spec`. We can also tell `reader` how to format the columns we're importing. 

### Extract column specification

> "Extract the full column specification for the given imported data frame."

We can extract the column specifications using the `spec()` argument on the imported data file. 

```{r spec-read_delim, eval=FALSE, echo=TRUE}
file <- readr::read_delim(file = "age\tsex\tearn\n25\tM\t85.5\n32\tF\t92.75")
file
```

```{r file, echo=FALSE, eval=TRUE}
file <- readr::read_delim(file = "age\tsex\tearn\n25\tM\t85.5\n32\tF\t92.75", show_col_types = FALSE)
rmarkdown::paged_table(file)
```


```{r setup-file, include=FALSE}
file <- readr::read_delim(file = "age\tsex\tearn\n25\tM\t85.5\n32\tF\t92.75", show_col_types = FALSE)
```


```{r ex-file, exercise.setup = "setup-file", exercise=TRUE}
# pass the 'file' to spec()
spec(x = )
```


### Hide column specification

> "Hide col spec message."

If we don't want to see the output from the column specification, we can hide this using the `show_col_types = ` argument: 

Hide the column specifications using `show_col_types` and click 'Run Code' to see the imported file.

```{r show_col_types, exercise=TRUE}
# identical to:
# readr::read_csv(file = "https://bit.ly/01-file-csv", 
#                 show_col_types = )
readr::read_csv(file = "data/file.csv", show_col_types = )
```


### Select columns to import

> "Use names, position, or selection helpers."

Import only the `A` and `C` columns (as `c(A, C)`) using the `col_select` argument and click 'Run Code' to see the imported file.

```{r col_select, exercise=TRUE}
# identical to:
# readr::read_csv(file = "https://bit.ly/01-file-csv", 
#                                       col_select = )
readr::read_csv(file = "data/file.csv", 
                col_select = )
```


### Column specifications (notes)

Most of these options are available from the data import GUI in the **Environment** pane. After clicking on *Import Dataset*, you'll select *From Text (readr)*. Click on *Browse* and navigate to a plain text file (the `file.csv` is show below as an example):

```{r import-readr-gui-path.png, echo=FALSE, fig.align='center', out.height='80%', out.width='80%'}
knitr::include_graphics(path = "https://raw.githubusercontent.com/mjfrigaard/learnr-cheatsheets/main/rscs-01-import/www/import-readr-gui-path.png")
```

You'll see a preview of the data file in the **Data Preview** section, with each column name and format. I've indicated the options we've covered in the **Import Options** section: 

```{r import-readr-gui-options.png, echo=FALSE, fig.align='center', out.height='90%', out.width='90%'}
knitr::include_graphics(path = "https://raw.githubusercontent.com/mjfrigaard/learnr-cheatsheets/main/rscs-01-import/www/import-readr-gui-options.png")
```

Next to the **Import Options** there is a **Code Preview** section that will create the code needed to import what you see in the **Data Preview** section. 

```{r import-readr-gui-code.png, echo=FALSE, fig.align='center', out.height='90%', out.width='90%'}
knitr::include_graphics(path = "https://raw.githubusercontent.com/mjfrigaard/learnr-cheatsheets/main/rscs-01-import/www/import-readr-gui-code.png")
```

Changes to the **Import Options** will cause changes in the **Code Preview**. Below I change the *Skip*, *First Row as Names*, and *Open Data Viewer* options: 

```{r import-readr-gui-options-alt.png, echo=FALSE, fig.align='center', out.height='90%', out.width='90%'}
knitr::include_graphics(path = "https://raw.githubusercontent.com/mjfrigaard/learnr-cheatsheets/main/rscs-01-import/www/import-readr-gui-options-alt.png")
```

And we can see the corresponding changes to the **Code Preview** section:

```{r import-readr-gui-code-alt.png, echo=FALSE, fig.align='center', out.height='90%', out.width='90%'}
knitr::include_graphics(path = "https://raw.githubusercontent.com/mjfrigaard/learnr-cheatsheets/main/rscs-01-import/www/import-readr-gui-code-alt.png")
```

Using the GUI is a helpful tool for learning how the R code works for importing code!

## Saving data with `readr`

To export data with `readr`, we can use any of the corresponding `write_*()` functions. Each of these take an object in the current environment (`x`) and the desired `file` path (including the file extension). 

We're going to use the handy [`fs::dir_tree()`](https://fs.r-lib.org/reference/dir_tree.html) function to verify the file exported correctly.

[`fs`](https://fs.r-lib.org/index.html) ('Filesystem') is a great package full of useful functions for manipulating and displaying folder and file information.

<!--
```{r prepare-flights}
nycflights <- nycflights13::flights
```

```{r filter, exercise=TRUE, exercise.setup = "prepare-flights"}
# Change the filter to select February rather than January
filter(nycflights, month == 1)
```

```{r arrange, exercise=TRUE, exercise.setup = "prepare-flights"}
# Change the sort order to Ascending
arrange(nycflights, desc(arr_delay))
```
-->

```{bash prepare-readrexport}
mkdir processed-data
```


> "Write files with any delimiter."

Read `data/file.txt` into `file_txt`, export as `processed-data/file_txt.txt` (with `"|"` as a delimiter).

```{r write_delim-file_txt, exercise=TRUE, exercise.setup = "prepare-readrexport"}
# read from data/
file_txt <- readr::read_delim(file = "")
# export to from processed-data/
write_delim(file_txt, file = "", delim = " ")
# verify with fs::dir_tree("processed-data")
fs::dir_tree("")
```

 
> "Write a comma delimited file."

Read `data/file.csv` into `file_csv`, export as `processed-data/file_csv.csv` 

```{r file_csv-write_csv, exercise=TRUE, exercise.setup = "prepare-readrexport"}
# read from data/
file_csv <- readr::read_csv(file = "")
# export to from processed-data/
write_csv(x = file_csv, file = "") 
# verify with fs::dir_tree("processed-data")
fs::dir_tree("")
```


> "Write a semicolon delimited file."

Read `data/file2.csv` into `file2_csv`, export as `processed-data/file2_csv.csv` 

```{r file2_csv-write_csv2, exercise=TRUE, exercise.setup = "prepare-readrexport"}
# read from data/
file2_csv <- readr::read_csv2(file = "")
# export to from processed-data/
write_csv2(x = file2_csv, file =  "")
# verify with fs::dir_tree("processed-data")
fs::dir_tree("")
```


> "Write a tab delimited file."

Read `data/file.tsv` into `file_tsv`, export as `processed-data/file_tsv.tsv` 

```{r file_tsv-write_tsv, exercise=TRUE, exercise.setup = "prepare-readrexport"}
# read from data/
file_tsv <- readr::read_tsv(file = " ")
# export to from processed-data/
write_tsv(x = file_tsv, file = " ") 
# verify with fs::dir_tree("processed-data")
fs::dir_tree("")
```


## Excel files with `readxl`

Microsoft Excel files are commonly used for data entry and storage. Despite being a proprietary format, we're able to import these files using the `readxl` package. Our excel file has the following contents: 

```{r excel-file.png, echo=FALSE, fig.align='center', out.height='90%', out.width='90%'}
knitr::include_graphics(path = "https://raw.githubusercontent.com/mjfrigaard/learnr-cheatsheets/main/rscs-01-import/www/excel-file.png")
```

We'll proceed as though they've been downloaded into a local `data/readxl/` folder.

### Read files 

`readxl` comes with three functions for reading Excel files: `read_excel()`, `read_xls()`, and `read_xlxs()`

### Print sheets 

> "Get a vector of sheet names."

The best place to start is with `excel_sheets()`, which tells us the names of the sheets in an Excel file. 

Click Run Code:

```{r excel_sheets, exercise=TRUE}
excel_sheets(path = "data/readxl/readxl-data.xlsx")
```

We can see this file has three sheets: `"f1.csv"`, `"f2.csv"`, `"f3.csv"`

### Read sheets

> "Specify which sheet to read by position or name."

If we want to import a sheet from the `readxl-data.xlsx` file, we can use the `read_excel()` function and specify the sheet name or position with the `sheet` argument.

Position is numeric, with `1` being the first sheet. 

```{r read_excel-f1-position, exercise=TRUE}
read_excel(path = "data/readxl/readxl-data.xlsx", 
    sheet = 1)
```

```{r read_excel-f1-position-print, echo=FALSE}
# # A tibble: 3 × 3
# 
#       A     B     C
#   <dbl> <dbl> <dbl>
# 1     2   4.5     3
# 2     1   7       4
# 3    NA   8       2
```


If we want to use the name of the sheet, we must supply this as a string (in quotes). Import only the `"f1.csv"` sheet in the code chunk below:

```{r read_excel-f1-name, exercise=TRUE}
read_excel(path = "data/readxl/readxl-data.xlsx", 
    sheet = )
```

```{r read_excel-f1-name-print, echo=FALSE}
# # A tibble: 3 × 3
# 
#       A     B     C
#   <dbl> <dbl> <dbl>
# 1     2   4.5     3
# 2     1   7       4
# 3    NA   8       2
```

Just like the output from `excel_sheets()` above!

### Read multiple sheets

If we want to import all the sheets in `readxl-data`, we can combine `excel_sheets()` with `read_excel()` with [`map_dfr()`](https://purrr.tidyverse.org/reference/map.html) from the [`purrr` package](https://purrr.tidyverse.org/index.html). 

> 1. Get a vector of sheet names from the file path.  
> 2. Set the vector names to be the sheet names.   
> 3. Use `purrr::map_dfr()` to read multiple files into one data frame.  

I'll go into slightly more detail about what the code below is doing:

1. We assign the local path to a character string, `path`  
2. We then pipe `path` to `excel_sheets()`, and we know what this output will be from the step above (`"f1.csv"`, `"f2.csv"`, `"f3.csv"`)  
3. The `purrr::set_names()` names each item in `path`, turning it into this: `f1.csv = "f1.csv"`, `f2.csv = "f2.csv"`, `f3.csv = "f3.csv"`  
4. We then passed this named vector to the `.x` argument in the `map_dfr()` function, and we pass `read_excel()` to the `.f` argument    
5. The `read_excel()` function has a `path` argument, and we will pass the original `path` vector (where the file is located)  

```{r imoport-multiple-excel, exercise=TRUE}
path <- "data/readxl/readxl-data.xlsx"
path %>% 
    excel_sheets() %>% 
    purrr::set_names() %>% 
    purrr::map_dfr(.x = ., .f = read_excel, path = path)
```

```{r map-dfr-f1-f3, echo=FALSE}
# # A tibble: 9 × 3     
#                                                                 
#       A     B     C
#   <dbl> <dbl> <dbl>
# 1     2   4.5     3
# 2     1   7       4
# 3    NA   8       2
# 4     9   4.6     2
# 5     1   7.2     5
# 6     4   3      NA
# 7    NA   2.2     5
# 8     4   5       3
# 9     1   2       6
```


The `map_dfr()` function stands for "map data frame, row-bind", which means all the data have been 'stacked' into a long data format.  

This is identical to (click Run Code): 

```{r import-sheets, exercise=TRUE}
# import sheets
f1 <- read_excel(path = "data/readxl/readxl-data.xlsx", 
    sheet = 1)
f2 <- read_excel(path = "data/readxl/readxl-data.xlsx", 
    sheet = 2)
f3 <- read_excel(path = "data/readxl/readxl-data.xlsx", 
    sheet = 3)
# bind together 
bind_rows(f1, f2, f3)
```

Obviously we'd want to use the `map_dfr()` function to avoid a lot of copying and pasting. You can read more about Excel workflows on the [`readxl` website](https://readxl.tidyverse.org/).

### Column specification 

> "Column specifications define what data type each column of a file will be imported as."

Specify the column types with the `col_types` argument (`"text"`) in the `f1.csv` sheet.

```{r col_types, exercise = TRUE}
read_excel(path = "data/readxl/readxl-data.xlsx", 
    sheet = " ", col_types = " ")
```


The options for `col_types` are: 

- `"skip"`  
- `"guess"` = default  
- `logical`   
- `numeric`  
- `text`  
- `date`  
- `list`  

When providing column types, you must either 1) enter nothing (in which case `readxl` will guess the column type based on the contents), 2) enter a single column type for all columns (like we did above with `"text"`), or 3) enter one column type for each column in the data file.

I've included the data types for each option of the `col_types` argument below:

```{r reactable-types, echo=FALSE, eval=TRUE}
reactable::reactable(data = 
tibble::tribble(
    ~logical, ~numeric,   ~text,        ~date,   ~list,
        TRUE,        2, "hello", "1947-01-08", "hello",
       FALSE,     3.45, "world", "1956-10-21",     "1"
    ) %>% mutate(date = lubridate::as_date(date)))
```


## Export data with writexl

If we have a dataset in our R environment we want to write to an Excel sheet, we can do this with either `writexl`. The `writexl` package is lightweight and only has a single function for writing data frames to excel, `write_xlsx()`. 

If you have a multiple data frames you'd like to export into an excel file with multiple sheets, you'll need to store these in a named list of data frames. 

Below is an example of how to do this with `purrr` and `readxl`. Instead of using `purrr`'s  `map_dfr()`, we use `map()` because it returns a list. 

```{r excel_data, exercise=TRUE}
path <- "data/readxl/readxl-data.xlsx"
excel_data <- path %>% 
     excel_sheets() %>% 
     purrr::set_names() %>% 
     purrr::map(.x = ., .f = read_excel, path = path)
excel_data
```


Now we'll create a directory for the output from `writexl` in our `data/` folder, then we can export the `excel_data` list directly to this path (because it's already a named list).

```{r prepare-writexl-excel_data}
path <- "data/readxl/readxl-data.xlsx"
excel_data <- path %>% 
     excel_sheets() %>% 
     purrr::set_names() %>% 
     purrr::map(.x = ., .f = read_excel, path = path)
excel_data
```


```{r create-writexl, exercise=TRUE, exercise.setup = "prepare-writexl-excel_data"}
fs::dir_create("data/writexl/")
write_xlsx(x = excel_data, 
    path = "data/writexl/excel_data.xlsx")
# verify
fs::dir_tree("data")
```

This gives us the following `excel_data.xlsx` file:

```{r excel-data-export.png, eval=TRUE, echo=FALSE, fig.align='center', out.height='90%', out.width='90%'}
knitr::include_graphics(path = "https://raw.githubusercontent.com/mjfrigaard/learnr-cheatsheets/main/rscs-01-import/www/excel-data-export.png")
```

## Export data with openxlsx

Another option is the [`openxlsx`](https://ycphs.github.io/openxlsx/index.html) package, which requires more code but has more options. 

`openxlsx` allows us to create an Excel workbook (`createWorkbook()`), name the sheets (`addWorksheet()`), and write data files to the sheets with a variety of formatting options (`writeDataTable()` and `saveWorkbook()`). 

```{r prepare-openxlsx-excel_data}
path <- "data/readxl/readxl-data.xlsx"
excel_data <- path %>% 
     excel_sheets() %>% 
     purrr::set_names() %>% 
     purrr::map(.x = ., .f = read_excel, path = path)
excel_data
```

```{r openxlsx-options, exercise=TRUE, exercise.setup = "prepare-openxlsx-excel_data", exercise.lines=24}
# create folder for output
fs::dir_create("data/openxlsx/")
# create workbook 
workbook <- createWorkbook()
# add worksheets
addWorksheet(wb = workbook, sheetName = "file-01.csv")
addWorksheet(wb = workbook, sheetName = "file-02.csv")
addWorksheet(wb = workbook, sheetName = "file-03.csv")
# write data frames to sheets
writeDataTable(wb = workbook, 
    sheet = "file-02.csv", 
    x = excel_data$f2.csv)
writeDataTable(wb = workbook, 
    sheet = "file-01.csv", 
    x = excel_data$f1.csv)
writeDataTable(wb = workbook, 
    sheet = "file-03.csv", 
    x = excel_data$f3.csv)
# save workbook
saveWorkbook(wb = workbook, 
             file = "data/openxlsx/openxlsx-output.xlsx", 
             overwrite = TRUE)
# verify
fs::dir_tree("data/")
```

This gives us the following file: 

```{r openxlsx-export.png, eval=TRUE, echo=FALSE, fig.align='center', out.height='90%', out.width='90%'}
knitr::include_graphics(path = "https://raw.githubusercontent.com/mjfrigaard/learnr-cheatsheets/main/rscs-01-import/www/openxlsx-export.png")
```


You can read more about these options on the [`openxlsx` website](https://ycphs.github.io/openxlsx/articles/Introduction.html). 


## Import data with `googlesheets4`

Another common storage format for data is in Google sheets, which are similar to Microsoft Excel, but built to work within your web browser. 

We can import data from these files using the [`googlesheets4` package](https://googlesheets4.tidyverse.org/). 

### Authenticate 

If you have a Google account, you can authenticate the your account using the [`gs4_auth()` function](https://googlesheets4.tidyverse.org/reference/gs4_auth.html).

```{r gs4_auth, eval=FALSE}
gs4_auth()
Is it OK to cache OAuth access credentials in the folder ~/Library/Caches/gargle between R sessions?

1: Yes
2: No
```

You'll be taken to your web browser, asked sign in and/or to approve the authentication, then you'll see this message when it's complete: 

> `Authentication complete. Please close this page and return to R.`

### Read sheets 

I've stored the data from the previous sections in a Google sheet available at [this link](https://docs.google.com/spreadsheets/d/1jOmVxBfJesO7NRYyiT1Ox6k6hGTNX0DRm1ZzAZU2sEQ/edit?usp=sharing). 

```{r gs4-data.png, eval=TRUE, echo=FALSE, fig.align='center', out.height='90%', out.width='90%'}
knitr::include_graphics(path = "https://raw.githubusercontent.com/mjfrigaard/learnr-cheatsheets/main/rscs-01-import/www/gs4-data.png")
```

The link for these data is also available is below: 

```markdown
https://docs.google.com/spreadsheets/d/1jOmVxBfJesO7NRYyiT1Ox6k6hGTNX0DRm1ZzAZU2sEQ/edit?usp=sharing
```

The function for importing data from Google Sheets is `range_read()`. Copy the link above and paste it (in quotes) into the `range_read()` function below, along with the name of the sheet (`"file-01.csv"`). 

*We will also include the `gs4_deauth()` function, because this sheet is public and doesn't require authentication.*

```{r read_sheet, exercise=TRUE}
# de-authenticate
gs4_deauth()
range_read(
    ss = , 
    sheet = 
)
```

`googlesheets4` also has many of the same arguments as the `readxl` and `readr` packages. For example, we can specify a `range` of cells from a given sheet.    

```{r setup-range_read-args, include=FALSE}
gs4_deauth()
```

Change the `range` argument to `"file-02.csv!A1:B4"`  

```{r range_read-args, exercise=TRUE, exercise.setup = "setup-range_read-args"}
range_read(
    ss = "https://docs.google.com/spreadsheets/d/1jOmVxBfJesO7NRYyiT1Ox6k6hGTNX0DRm1ZzAZU2sEQ/edit?usp=sharing", 
    range = )
```

### Column specifications 

We can also specify the column types, but with slightly different syntax from `readxl` and `readr`: 

```{r setup-googlesheets4-col_types, include=FALSE}
gs4_deauth()
```

Use the code below to return the contents of `"file-03.csv"` as character: 

```{r googlesheets4-col_types, exercise=TRUE, exercise.setup = "setup-googlesheets4-col_types"}
range_read(
    ss = "https://docs.google.com/spreadsheets/d/1jOmVxBfJesO7NRYyiT1Ox6k6hGTNX0DRm1ZzAZU2sEQ/edit?usp=sharing", 
    sheet = ,
    col_types = 
        )
```

Other options for column formats are below:

- skip - `"_"` or `"-"`  
- guess - `"?"`  
- logical - `"l"`  
- integer - `"i"`  
- double - `"d"`  
- numeric - `"n"`  
- date - `"D"`  
- datetime - `"T"`  
- character - `"c"`  
- list-column - `"L"`  
- cell - `"C"` Returns list of raw cell data.

```{r googlesheets4-column-types, echo=FALSE}
reactable::reactable(data = 
tibble::tribble(
          ~l,       ~n,      ~c,           ~D,      ~L,
        TRUE,        2, "hello", "1947-01-08", "hello",
       FALSE,     3.45, "world", "1956-10-21",     "1"
    ) %>% mutate(D = lubridate::as_date(D)))
```

### Metadata 

```{r setup-gs4_get, include=FALSE}
gs4_deauth()
```

If we'd like to know the metadata (data about the data) in a Google Sheet, we can use the `gs4_get()` function. 

```markdown
https://docs.google.com/spreadsheets/d/1jOmVxBfJesO7NRYyiT1Ox6k6hGTNX0DRm1ZzAZU2sEQ/edit?usp=sharing
```

Pass the URL from the sheet above to `ss` argument in `gs4_get()` below:

```{r gs4_get, exercise=TRUE, exercise.setup = "setup-gs4_get"}
gs4_get(ss = )
```

If you use Google sheets regularly and other Google tools, check out the [`googledrive` package](https://googledrive.tidyverse.org/) for managing Google files.  

## Conclusion

We've covered three of the most common methods for importing data into RStudio: 

1. `readr` for plain text files  
2. `readxl` for Microsoft Excel files  
3. `googlesheets4` for reading Google Sheets  

We also covered how to export data with `writexl` and `openxlsx`. 

All of the information in this tutorial is in the data import cheatsheet from RStudio, which you can access [here](https://www.rstudio.com/resources/cheatsheets/). 

If you'd like the data files used in this tutorial, you can download them from the [Github repo](https://github.com/mjfrigaard/learnr-cheatsheets).  

<div data-iframe-height></div>
